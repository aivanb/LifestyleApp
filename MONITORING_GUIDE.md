# Workout Tracking System - Monitoring Guide

## ðŸ“Š Monitoring Overview

This guide covers comprehensive monitoring strategies for the Workout Tracking System, including application performance, infrastructure monitoring, and alerting systems.

## ðŸ—ï¸ Monitoring Architecture

### Monitoring Stack
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Monitoring Stack                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Application Monitoring (APM)                           â”‚
â”‚ 2. Infrastructure Monitoring (System Resources)           â”‚
â”‚ 3. Database Monitoring (Query Performance)                â”‚
â”‚ 4. Network Monitoring (Connectivity & Latency)           â”‚
â”‚ 5. Security Monitoring (Threat Detection)                 â”‚
â”‚ 6. Business Metrics (User Activity & Growth)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Monitoring Components
- **Metrics Collection**: Prometheus, Grafana
- **Log Aggregation**: ELK Stack (Elasticsearch, Logstash, Kibana)
- **Alerting**: AlertManager, PagerDuty
- **APM**: New Relic, DataDog, or custom solutions
- **Uptime Monitoring**: Pingdom, UptimeRobot

## ðŸ” Application Performance Monitoring

### Django APM Implementation
```python
# Custom APM middleware
import time
import logging
from django.db import connection
from django.core.cache import cache
import psutil

logger = logging.getLogger('apm')

class APMMiddleware:
    def __init__(self, get_response):
        self.get_response = get_response
    
    def __call__(self, request):
        start_time = time.time()
        queries_before = len(connection.queries)
        
        # Add request start time
        request.start_time = start_time
        
        response = self.get_response(request)
        
        end_time = time.time()
        queries_after = len(connection.queries)
        
        # Calculate metrics
        response_time = end_time - start_time
        query_count = queries_after - queries_before
        
        # Log performance metrics
        self.log_performance_metrics(request, response, response_time, query_count)
        
        # Check for performance issues
        self.check_performance_thresholds(request, response_time, query_count)
        
        return response
    
    def log_performance_metrics(self, request, response, response_time, query_count):
        """Log performance metrics"""
        metrics = {
            'timestamp': time.time(),
            'path': request.path,
            'method': request.method,
            'status_code': response.status_code,
            'response_time': response_time,
            'query_count': query_count,
            'user_id': getattr(request.user, 'id', None),
            'ip_address': request.META.get('REMOTE_ADDR'),
            'user_agent': request.META.get('HTTP_USER_AGENT'),
        }
        
        logger.info(f"APM Metrics: {metrics}")
        
        # Store in cache for monitoring
        cache_key = f"apm_metrics_{int(time.time())}"
        cache.set(cache_key, metrics, timeout=300)
    
    def check_performance_thresholds(self, request, response_time, query_count):
        """Check performance thresholds and alert if needed"""
        if response_time > 1.0:  # 1 second threshold
            logger.warning(f"Slow request: {request.path} took {response_time:.2f}s")
        
        if query_count > 20:  # 20 queries threshold
            logger.warning(f"High query count: {request.path} executed {query_count} queries")
        
        if response_time > 5.0:  # 5 second threshold
            logger.error(f"Very slow request: {request.path} took {response_time:.2f}s")
```

### Custom Metrics Collection
```python
# Custom metrics collector
class MetricsCollector:
    def __init__(self):
        self.metrics = {}
        self.counters = {}
        self.gauges = {}
        self.histograms = {}
    
    def increment_counter(self, name, value=1, tags=None):
        """Increment a counter metric"""
        if name not in self.counters:
            self.counters[name] = 0
        self.counters[name] += value
        
        # Send to external metrics service
        self.send_metric('counter', name, value, tags)
    
    def set_gauge(self, name, value, tags=None):
        """Set a gauge metric"""
        self.gauges[name] = value
        
        # Send to external metrics service
        self.send_metric('gauge', name, value, tags)
    
    def record_histogram(self, name, value, tags=None):
        """Record a histogram metric"""
        if name not in self.histograms:
            self.histograms[name] = []
        self.histograms[name].append(value)
        
        # Send to external metrics service
        self.send_metric('histogram', name, value, tags)
    
    def send_metric(self, metric_type, name, value, tags=None):
        """Send metric to external service"""
        # Implementation depends on metrics service
        pass

# Usage examples
metrics = MetricsCollector()

# Track API calls
metrics.increment_counter('api.calls', tags={'endpoint': '/workouts/'})

# Track response times
metrics.record_histogram('api.response_time', 0.5, tags={'endpoint': '/workouts/'})

# Track active users
metrics.set_gauge('users.active', 150)
```

### Database Performance Monitoring
```python
# Database performance monitoring
class DatabaseMonitor:
    def __init__(self):
        self.slow_queries = []
        self.query_stats = {}
    
    def log_slow_queries(self):
        """Log slow database queries"""
        for query in connection.queries:
            if float(query['time']) > 0.1:  # 100ms threshold
                slow_query = {
                    'sql': query['sql'],
                    'time': float(query['time']),
                    'timestamp': time.time(),
                }
                self.slow_queries.append(slow_query)
                
                logger.warning(f"Slow query: {query['sql']} - {query['time']}s")
    
    def get_query_stats(self):
        """Get database query statistics"""
        total_queries = len(connection.queries)
        total_time = sum(float(q['time']) for q in connection.queries)
        
        return {
            'total_queries': total_queries,
            'total_time': total_time,
            'average_time': total_time / total_queries if total_queries > 0 else 0,
            'slow_queries': len(self.slow_queries),
        }
    
    def optimize_queries(self):
        """Suggest query optimizations"""
        suggestions = []
        
        for query in self.slow_queries:
            if 'SELECT *' in query['sql']:
                suggestions.append("Use specific fields instead of SELECT *")
            
            if 'ORDER BY' in query['sql'] and 'LIMIT' not in query['sql']:
                suggestions.append("Consider adding LIMIT to ORDER BY queries")
            
            if 'JOIN' in query['sql']:
                suggestions.append("Check if JOIN can be optimized with indexes")
        
        return suggestions
```

## ðŸ–¥ï¸ Infrastructure Monitoring

### System Resource Monitoring
```python
# System resource monitoring
import psutil
import time

class SystemMonitor:
    def __init__(self):
        self.metrics = {}
    
    def get_cpu_metrics(self):
        """Get CPU metrics"""
        cpu_percent = psutil.cpu_percent(interval=1)
        cpu_count = psutil.cpu_count()
        cpu_freq = psutil.cpu_freq()
        
        return {
            'cpu_percent': cpu_percent,
            'cpu_count': cpu_count,
            'cpu_freq': cpu_freq.current if cpu_freq else None,
            'load_average': psutil.getloadavg(),
        }
    
    def get_memory_metrics(self):
        """Get memory metrics"""
        memory = psutil.virtual_memory()
        swap = psutil.swap_memory()
        
        return {
            'memory_total': memory.total,
            'memory_available': memory.available,
            'memory_percent': memory.percent,
            'memory_used': memory.used,
            'swap_total': swap.total,
            'swap_used': swap.used,
            'swap_percent': swap.percent,
        }
    
    def get_disk_metrics(self):
        """Get disk metrics"""
        disk = psutil.disk_usage('/')
        disk_io = psutil.disk_io_counters()
        
        return {
            'disk_total': disk.total,
            'disk_used': disk.used,
            'disk_free': disk.free,
            'disk_percent': (disk.used / disk.total) * 100,
            'disk_read_bytes': disk_io.read_bytes if disk_io else 0,
            'disk_write_bytes': disk_io.write_bytes if disk_io else 0,
        }
    
    def get_network_metrics(self):
        """Get network metrics"""
        network_io = psutil.net_io_counters()
        
        return {
            'bytes_sent': network_io.bytes_sent,
            'bytes_recv': network_io.bytes_recv,
            'packets_sent': network_io.packets_sent,
            'packets_recv': network_io.packets_recv,
        }
    
    def get_all_metrics(self):
        """Get all system metrics"""
        return {
            'timestamp': time.time(),
            'cpu': self.get_cpu_metrics(),
            'memory': self.get_memory_metrics(),
            'disk': self.get_disk_metrics(),
            'network': self.get_network_metrics(),
        }
```

### Service Monitoring
```bash
#!/bin/bash
# Service monitoring script

echo "=== Service Monitoring ==="

# Check service status
services=("workout-tracker" "nginx" "mysql" "redis")

for service in "${services[@]}"; do
    if systemctl is-active --quiet $service; then
        echo "âœ… $service: Running"
    else
        echo "âŒ $service: Not running"
        systemctl status $service --no-pager
    fi
done

# Check service health
echo "=== Service Health ==="

# Check Django application
response=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8000/api/health/)
if [ $response -eq 200 ]; then
    echo "âœ… Django Application: Healthy"
else
    echo "âŒ Django Application: Unhealthy (HTTP $response)"
fi

# Check Nginx
response=$(curl -s -o /dev/null -w "%{http_code}" http://localhost/nginx_status)
if [ $response -eq 200 ]; then
    echo "âœ… Nginx: Healthy"
else
    echo "âŒ Nginx: Unhealthy (HTTP $response)"
fi

# Check MySQL
mysql -u workout_user -p workout_tracker -e "SELECT 1;" 2>/dev/null
if [ $? -eq 0 ]; then
    echo "âœ… MySQL: Healthy"
else
    echo "âŒ MySQL: Unhealthy"
fi

# Check Redis
redis-cli ping 2>/dev/null | grep -q PONG
if [ $? -eq 0 ]; then
    echo "âœ… Redis: Healthy"
else
    echo "âŒ Redis: Unhealthy"
fi
```

## ðŸ“Š Database Monitoring

### MySQL Performance Monitoring
```sql
-- MySQL performance monitoring queries

-- Check slow queries
SHOW VARIABLES LIKE 'slow_query_log';
SHOW VARIABLES LIKE 'long_query_time';

-- Check query cache
SHOW STATUS LIKE 'Qcache_hits';
SHOW STATUS LIKE 'Qcache_misses';
SHOW STATUS LIKE 'Qcache_inserts';

-- Check connections
SHOW STATUS LIKE 'Connections';
SHOW STATUS LIKE 'Max_used_connections';
SHOW STATUS LIKE 'Threads_connected';
SHOW STATUS LIKE 'Threads_running';

-- Check table locks
SHOW STATUS LIKE 'Table_locks_waited';
SHOW STATUS LIKE 'Table_locks_immediate';

-- Check InnoDB status
SHOW STATUS LIKE 'Innodb_buffer_pool_hit_rate';
SHOW STATUS LIKE 'Innodb_log_waits';
SHOW STATUS LIKE 'Innodb_row_lock_waits';

-- Check table sizes
SELECT 
    table_name,
    ROUND(((data_length + index_length) / 1024 / 1024), 2) AS "Size (MB)",
    table_rows
FROM information_schema.TABLES
WHERE table_schema = 'workout_tracker'
ORDER BY (data_length + index_length) DESC;
```

### Database Health Check
```python
# Database health check
class DatabaseHealthCheck:
    def __init__(self):
        self.health_status = {}
    
    def check_connection(self):
        """Check database connection"""
        try:
            with connection.cursor() as cursor:
                cursor.execute("SELECT 1")
            return True
        except Exception as e:
            logger.error(f"Database connection failed: {e}")
            return False
    
    def check_slow_queries(self):
        """Check for slow queries"""
        slow_queries = []
        for query in connection.queries:
            if float(query['time']) > 0.1:  # 100ms threshold
                slow_queries.append({
                    'sql': query['sql'],
                    'time': float(query['time']),
                })
        return slow_queries
    
    def check_table_sizes(self):
        """Check table sizes"""
        with connection.cursor() as cursor:
            cursor.execute("""
                SELECT 
                    table_name,
                    ROUND(((data_length + index_length) / 1024 / 1024), 2) AS size_mb
                FROM information_schema.TABLES
                WHERE table_schema = 'workout_tracker'
                ORDER BY (data_length + index_length) DESC
            """)
            return cursor.fetchall()
    
    def check_index_usage(self):
        """Check index usage"""
        with connection.cursor() as cursor:
            cursor.execute("""
                SELECT 
                    table_name,
                    index_name,
                    cardinality
                FROM information_schema.STATISTICS
                WHERE table_schema = 'workout_tracker'
                ORDER BY cardinality DESC
            """)
            return cursor.fetchall()
    
    def run_health_check(self):
        """Run complete database health check"""
        self.health_status = {
            'connection': self.check_connection(),
            'slow_queries': self.check_slow_queries(),
            'table_sizes': self.check_table_sizes(),
            'index_usage': self.check_index_usage(),
            'timestamp': time.time(),
        }
        return self.health_status
```

## ðŸ”” Alerting System

### Alert Configuration
```python
# Alert configuration
class AlertManager:
    def __init__(self):
        self.alerts = []
        self.thresholds = {
            'cpu_percent': 80,
            'memory_percent': 80,
            'disk_percent': 90,
            'response_time': 1.0,
            'error_rate': 5.0,
            'slow_queries': 10,
        }
    
    def check_thresholds(self, metrics):
        """Check metrics against thresholds"""
        alerts = []
        
        # CPU threshold
        if metrics.get('cpu_percent', 0) > self.thresholds['cpu_percent']:
            alerts.append({
                'type': 'high_cpu',
                'value': metrics['cpu_percent'],
                'threshold': self.thresholds['cpu_percent'],
                'severity': 'warning',
            })
        
        # Memory threshold
        if metrics.get('memory_percent', 0) > self.thresholds['memory_percent']:
            alerts.append({
                'type': 'high_memory',
                'value': metrics['memory_percent'],
                'threshold': self.thresholds['memory_percent'],
                'severity': 'warning',
            })
        
        # Disk threshold
        if metrics.get('disk_percent', 0) > self.thresholds['disk_percent']:
            alerts.append({
                'type': 'high_disk',
                'value': metrics['disk_percent'],
                'threshold': self.thresholds['disk_percent'],
                'severity': 'critical',
            })
        
        # Response time threshold
        if metrics.get('response_time', 0) > self.thresholds['response_time']:
            alerts.append({
                'type': 'slow_response',
                'value': metrics['response_time'],
                'threshold': self.thresholds['response_time'],
                'severity': 'warning',
            })
        
        return alerts
    
    def send_alert(self, alert):
        """Send alert notification"""
        # Implementation depends on alerting service
        # - Email notifications
        # - Slack notifications
        # - PagerDuty integration
        # - SMS notifications
        
        logger.warning(f"Alert: {alert['type']} - {alert['value']} > {alert['threshold']}")
        
        # Store alert for tracking
        self.alerts.append({
            **alert,
            'timestamp': time.time(),
            'resolved': False,
        })
    
    def resolve_alert(self, alert_type):
        """Resolve alert"""
        for alert in self.alerts:
            if alert['type'] == alert_type and not alert['resolved']:
                alert['resolved'] = True
                alert['resolved_at'] = time.time()
                logger.info(f"Alert resolved: {alert_type}")
```

### Health Check Endpoint
```python
# Health check endpoint
from django.http import JsonResponse
from django.db import connection
from django.core.cache import cache
import psutil
import time

def health_check(request):
    """Comprehensive health check endpoint"""
    health_status = {
        'status': 'healthy',
        'timestamp': timezone.now().isoformat(),
        'checks': {}
    }
    
    # Database check
    try:
        with connection.cursor() as cursor:
            cursor.execute("SELECT 1")
        health_status['checks']['database'] = 'healthy'
    except Exception as e:
        health_status['checks']['database'] = f'unhealthy: {str(e)}'
        health_status['status'] = 'unhealthy'
    
    # Cache check
    try:
        cache.set('health_check', 'test', 10)
        cache.get('health_check')
        health_status['checks']['cache'] = 'healthy'
    except Exception as e:
        health_status['checks']['cache'] = f'unhealthy: {str(e)}'
        health_status['status'] = 'unhealthy'
    
    # Disk space check
    try:
        disk_usage = psutil.disk_usage('/')
        free_percent = (disk_usage.free / disk_usage.total) * 100
        if free_percent < 10:
            health_status['checks']['disk'] = f'unhealthy: {free_percent:.1f}% free'
            health_status['status'] = 'unhealthy'
        else:
            health_status['checks']['disk'] = f'healthy: {free_percent:.1f}% free'
    except Exception as e:
        health_status['checks']['disk'] = f'unhealthy: {str(e)}'
        health_status['status'] = 'unhealthy'
    
    # Memory check
    try:
        memory = psutil.virtual_memory()
        if memory.percent > 90:
            health_status['checks']['memory'] = f'unhealthy: {memory.percent}% used'
            health_status['status'] = 'unhealthy'
        else:
            health_status['checks']['memory'] = f'healthy: {memory.percent}% used'
    except Exception as e:
        health_status['checks']['memory'] = f'unhealthy: {str(e)}'
        health_status['status'] = 'unhealthy'
    
    # CPU check
    try:
        cpu_percent = psutil.cpu_percent(interval=1)
        if cpu_percent > 90:
            health_status['checks']['cpu'] = f'unhealthy: {cpu_percent}% used'
            health_status['status'] = 'unhealthy'
        else:
            health_status['checks']['cpu'] = f'healthy: {cpu_percent}% used'
    except Exception as e:
        health_status['checks']['cpu'] = f'unhealthy: {str(e)}'
        health_status['status'] = 'unhealthy'
    
    return JsonResponse(health_status)
```

## ðŸ“ˆ Business Metrics

### User Activity Monitoring
```python
# User activity monitoring
class UserActivityMonitor:
    def __init__(self):
        self.activity_metrics = {}
    
    def track_user_login(self, user_id):
        """Track user login"""
        self.increment_metric('user_logins', user_id)
        self.set_metric('last_login', user_id, time.time())
    
    def track_workout_creation(self, user_id):
        """Track workout creation"""
        self.increment_metric('workouts_created', user_id)
        self.increment_metric('total_workouts_created')
    
    def track_workout_logging(self, user_id):
        """Track workout logging"""
        self.increment_metric('workouts_logged', user_id)
        self.increment_metric('total_workouts_logged')
    
    def track_split_creation(self, user_id):
        """Track split creation"""
        self.increment_metric('splits_created', user_id)
        self.increment_metric('total_splits_created')
    
    def get_user_activity_summary(self, user_id):
        """Get user activity summary"""
        return {
            'user_id': user_id,
            'logins': self.get_metric('user_logins', user_id),
            'workouts_created': self.get_metric('workouts_created', user_id),
            'workouts_logged': self.get_metric('workouts_logged', user_id),
            'splits_created': self.get_metric('splits_created', user_id),
            'last_login': self.get_metric('last_login', user_id),
        }
    
    def get_system_activity_summary(self):
        """Get system activity summary"""
        return {
            'total_workouts_created': self.get_metric('total_workouts_created'),
            'total_workouts_logged': self.get_metric('total_workouts_logged'),
            'total_splits_created': self.get_metric('total_splits_created'),
            'active_users': self.get_active_users_count(),
        }
    
    def increment_metric(self, metric_name, user_id=None):
        """Increment metric"""
        key = f"{metric_name}_{user_id}" if user_id else metric_name
        if key not in self.activity_metrics:
            self.activity_metrics[key] = 0
        self.activity_metrics[key] += 1
    
    def set_metric(self, metric_name, user_id, value):
        """Set metric value"""
        key = f"{metric_name}_{user_id}"
        self.activity_metrics[key] = value
    
    def get_metric(self, metric_name, user_id=None):
        """Get metric value"""
        key = f"{metric_name}_{user_id}" if user_id else metric_name
        return self.activity_metrics.get(key, 0)
    
    def get_active_users_count(self):
        """Get count of active users"""
        # Implementation depends on how you define "active"
        # Could be users who logged in within last 24 hours
        return len([k for k in self.activity_metrics.keys() if k.startswith('last_login_')])
```

### Growth Metrics
```python
# Growth metrics tracking
class GrowthMetrics:
    def __init__(self):
        self.growth_data = {}
    
    def track_user_registration(self, user_id, registration_date):
        """Track user registration"""
        if 'user_registrations' not in self.growth_data:
            self.growth_data['user_registrations'] = []
        
        self.growth_data['user_registrations'].append({
            'user_id': user_id,
            'date': registration_date,
        })
    
    def track_feature_usage(self, feature_name, user_id, usage_date):
        """Track feature usage"""
        if 'feature_usage' not in self.growth_data:
            self.growth_data['feature_usage'] = {}
        
        if feature_name not in self.growth_data['feature_usage']:
            self.growth_data['feature_usage'][feature_name] = []
        
        self.growth_data['feature_usage'][feature_name].append({
            'user_id': user_id,
            'date': usage_date,
        })
    
    def calculate_growth_rate(self, metric_name, days=30):
        """Calculate growth rate for a metric"""
        if metric_name not in self.growth_data:
            return 0
        
        data = self.growth_data[metric_name]
        if len(data) < 2:
            return 0
        
        # Calculate growth rate over specified days
        recent_data = [d for d in data if d['date'] >= timezone.now() - timedelta(days=days)]
        older_data = [d for d in data if d['date'] < timezone.now() - timedelta(days=days)]
        
        if not older_data:
            return 0
        
        recent_count = len(recent_data)
        older_count = len(older_data)
        
        if older_count == 0:
            return 0
        
        growth_rate = ((recent_count - older_count) / older_count) * 100
        return growth_rate
    
    def get_growth_summary(self):
        """Get growth summary"""
        return {
            'user_growth_rate': self.calculate_growth_rate('user_registrations'),
            'feature_usage_growth': {
                feature: self.calculate_growth_rate(feature)
                for feature in self.growth_data.get('feature_usage', {}).keys()
            },
            'total_users': len(self.growth_data.get('user_registrations', [])),
            'total_feature_usage': sum(
                len(usage) for usage in self.growth_data.get('feature_usage', {}).values()
            ),
        }
```

## ðŸ“Š Monitoring Dashboard

### Grafana Dashboard Configuration
```json
{
  "dashboard": {
    "title": "Workout Tracker Monitoring",
    "panels": [
      {
        "title": "System CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "cpu_percent",
            "legendFormat": "CPU Usage %"
          }
        ]
      },
      {
        "title": "System Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "memory_percent",
            "legendFormat": "Memory Usage %"
          }
        ]
      },
      {
        "title": "API Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "api_response_time",
            "legendFormat": "Response Time (ms)"
          }
        ]
      },
      {
        "title": "Database Query Count",
        "type": "graph",
        "targets": [
          {
            "expr": "database_query_count",
            "legendFormat": "Query Count"
          }
        ]
      },
      {
        "title": "Active Users",
        "type": "stat",
        "targets": [
          {
            "expr": "active_users",
            "legendFormat": "Active Users"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "error_rate",
            "legendFormat": "Error Rate %"
          }
        ]
      }
    ]
  }
}
```

### Monitoring Script
```bash
#!/bin/bash
# Monitoring script

echo "=== System Monitoring ==="

# Check system resources
echo "=== System Resources ==="
free -h
df -h
uptime

# Check service status
echo "=== Service Status ==="
systemctl is-active workout-tracker
systemctl is-active nginx
systemctl is-active mysql

# Check application health
echo "=== Application Health ==="
curl -s http://localhost:8000/api/health/ | jq .

# Check database performance
echo "=== Database Performance ==="
mysql -u workout_user -p workout_tracker -e "
SHOW STATUS LIKE 'Connections';
SHOW STATUS LIKE 'Max_used_connections';
SHOW STATUS LIKE 'Slow_queries';
"

# Check recent errors
echo "=== Recent Errors ==="
grep -i "error" /var/log/gunicorn/error.log | tail -5
grep -i "error" /var/log/nginx/error.log | tail -5

echo "Monitoring completed"
```

## ðŸ“‹ Monitoring Checklist

### Application Monitoring
- [ ] **APM Implementation**: Custom APM middleware
- [ ] **Performance Metrics**: Response time, query count, memory usage
- [ ] **Error Tracking**: Error logging and alerting
- [ ] **User Activity**: Track user interactions and feature usage
- [ ] **Business Metrics**: Track growth and engagement metrics
- [ ] **Health Checks**: Comprehensive health check endpoints

### Infrastructure Monitoring
- [ ] **System Resources**: CPU, memory, disk, network monitoring
- [ ] **Service Status**: Monitor all critical services
- [ ] **Database Performance**: Query performance and connection monitoring
- [ ] **Network Monitoring**: Connectivity and latency monitoring
- [ ] **Log Aggregation**: Centralized logging and analysis
- [ ] **Alerting**: Automated alerting for critical issues

### Security Monitoring
- [ ] **Failed Login Attempts**: Monitor authentication failures
- [ ] **Suspicious Activity**: Track unusual patterns
- [ ] **Access Logs**: Monitor access patterns and anomalies
- [ ] **Security Events**: Track security-related events
- [ ] **Vulnerability Scanning**: Regular security scans
- [ ] **Incident Response**: Automated incident response procedures

---

**Remember**: Monitoring is an ongoing process. Regular review and optimization of monitoring systems are essential for maintaining system reliability and performance.
